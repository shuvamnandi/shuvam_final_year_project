\chapter{Background}
\label{ch2_background}

\section{Coarse Grained FPGA Overlays}
Overlay architectures consist of a regular arrangement of coarse grained routing and compute resources. The key attraction of overlay architectures is software-like programmability through mapping from high level descriptions, application portability across devices, design reuse, fast compilation by avoiding the complex FPGA implementation flow, and hence, improved design productivity.
Another main advantage is rapid reconfiguration since the overlay architectures have smaller configuration data size due to the coarse granularity.
Accelerators can be described at a higher level of abstraction and compiling it for overlays is several orders of magnitude faster than for the fine grained FPGAs.
Researchers have proposed fine 
\cite{brant_zuma:_2012}, 
\cite{hubner_heterogeneous_2011} 
and coarse grained 
\cite{plessl_zippy_2005}, 
\cite{bergmann_quku:_2013},
\cite{coole_intermediate_2010},
\cite{capalija_high-performance_2013},
\cite{liu_soft_2013}, 
\cite{heyse_efficient_2013}                  
overlay architectures to abstract FPGA fabric resources.

%\input{figures_tex/overlay}


As shown in Fig. \ref{overlaydiagram}, coarse grained FPGA overlay architecture is a two-dimensional array of reconfigurable tiles, implemented on top of a commercial FPGA device.
Coarse grained tiles contains programmable processing elements (PEs) interconnected using programmable interconnect (PI) and the functions of the PE and the PI are controlled by configuration data.
The overlay overcomes the need for a full cycle through the vendor implementation tools, instead presenting a much simpler problem of placing arithmetic operations on an array of processing elements and routing data via an interconnect network.


 
Researchers have shown the effective use of coarse grained overlay architectures by pairing them with host processors as a coprocessor~\cite{cong2014fully,jsps2014-jain} or as a part of the processor's pipeline~\cite{benson2012design}. 
Fig. \ref{dyser_host} shows the integration of DySER~\cite{benson2012design, govindaraju2011dynamically} overlay into the pipeline of a processor.

\begin{figure}[!h]
	\centering
	%\includegraphics[width=15.5cm]{figures/dyser_host.png}
	\caption{DySER Interfacing with Host Processor~\cite{govindaraju2012dyser}} %\cite{avnet_2012}}
	\label{dyser_host}
\end{figure}

In DySER overlay, the functional unit (FU) provides resources for the mathematical and logical operations, and synchronization logic.
It receives its input values from the four neighbouring switches and outputs its result to the switch in the south-east direction.
The switches allow datapaths to be dynamically specialized. 
They form a on chip network that creates paths from inputs to the functional units, between functional units, and from functional units to outputs.
Fig. \ref{dyser_kernel} shows the mapping of kernels on DySER architecture.

\begin{figure}[!h]
	\centering
	%\includegraphics[width=16cm]{figures/kernels.png}
	\caption{Mapping of Kernels on DySER Architecture.}
	\label{dyser_kernel}
\end{figure}

One example of pairing the overlay (\ac{IF} Overlay~\cite{coole_intermediate_2010}) with a high performance ARM processor via an \ac{AXI} interface in a commercial computing platform (the Xilinx Zynq\cite{xilinx_zynq_2013}) is shown in Fig. \ref{jsps}.
Zynq platform partition the hardware into a \ac{PS}, containing one or more processors along with peripherals, bus and memory interfaces, and the \ac{PL} where custom hardware including an overlay can be implemented. 
The Xilinx-Zynq consists of a dual-core ARM Cortex A9 processor equipped with a double-precision Floating Point Unit (FPU), commonly used peripherals and reconfigurable fabric.


\begin{figure}[!h]
	\centering
	%\includegraphics[width=10cm]{figures/hybridplatform.pdf}
	\caption{Intermediate Fabric (IF) Interfacing with Host Processor~\cite{jsps2014-jain}} %\cite{avnet_2012}}
	\label{jsps}
\end{figure}

When paired as a coprocessor, run-time management, including overlay configuration loading, data communication, can be carried out using an operating system (Linux)~\cite{cong2014fully} and also using a commercial hypervisor~\cite{pham_microkernel_2013}.
Firstly, user needs to identify a kernel, to be implemented on top of overlay.
Then DFG can be extracted after compiling this code using compiler front-end.
After that a place and route tool can be used to map the DFG on top of overlay.
After generating configurations based on the placement and routing, kernel code can be transformed in the code containing overlay APIs. 


An overlay provides a leaner mechanism for hardware task management at runtime as there is no need to prepare distinct bitstreams in advance using vendor-specific compilation (synthesis, map, place and route) tools. Instead, the behaviour of the overlay can be modified using software defined overlay configurations. 
The possible configuration space and configuration data size is much smaller than for direct FPGA implementation of kernels because of the coarser granularity of the overlay. 
In the next section, we provide an overview of placement and routing for fine-grained and coarse-grained architectures.



\section{Placement and Routing}
In this section, we will discuss about placement and routing for fine grained and coarse grained architectures with the help of examples.
In case of fine-grained architectures, generally applications are described in hardware description language (HDL) such as Verilog/VHDL. The process of generating configuration data from HDL description can be divided into four major steps:
\begin{itemize}\itemsep1pt \parskip0pt
	\item Synthesis
	\item Technology Mapping
	\item Placement
	\item Routing
\end{itemize}

Synthesis step transforms the HDL to a hierarchical network of basic building blocks.
Given a set of library cells, technology mapping is generally defined as mapping the network to the library cells. In case of FPGAs, this library is composed of k-LUTs, flip-flops, basic arithmetic circuits like adders, and advanced hard blocks. Therefore, the technology mapping for FPGAs consists of transforming the Boolean network into a set of nodes.
Placement is the process of determining which logic blocks should be placed where. 
In other words, which specific logic blocks on FPGA should be used for a particular instance of a logic block of given network.
Routing is the process of finding routes so that all logic blocks
used in placement stage are properly connected. 


%There are many algorithms for placement like Serial Algorithm - Simulated Annealing and Analytical Based Method as well as Parallel Acceleration. For routing there exist serial algorithms like Geometric method and Boolean method as well as Hardware and Parallel Acceleration.

To give an example, Fig.~\ref*{verilog} shows HDL description of a compute kernel for accumulating four 16-bit numbers.
Fig.~\ref*{par_fine} shows the mapping of the description onto a fine-grained FPGA architecture.


%\input{figures_tex/verilog}

\begin{figure}[!h]
	\centering
	%\includegraphics[width=9cm]{figures/par_fine.png}
	\caption{Placement of Routing on Fine-grained architecture} %\cite{avnet_2012}}
	\label{par_fine}
\end{figure}


\begin{figure}[!h]
	\centering
	%\includegraphics[width=7cm]{figures/par_cg.png}
	\caption{Placement of Routing on Coarse-grained architecture} %\cite{avnet_2012}}
	\label{par_cg}
\end{figure}

Fig.~\ref*{par_cg} shows the mapping on a coarse grained architecture where each track is 16-bit wide and each functional unit (FU) is a 16-bit arithmetic operator.

